{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb74ee00-2a32-4191-b169-157cbbf7d5ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "import silver data"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window as W\n",
    "\n",
    "dbutils.widgets.text(\"catalog\", \"ptd_dev\")\n",
    "catalog       = dbutils.widgets.get(\"catalog\")\n",
    "spark.sql(f\"USE CATALOG {catalog}\")\n",
    "\n",
    "prices = spark.table(\"silver.prices_daily\")\n",
    "news = spark.table(\"silver.ticker_news_tone\").select(\"ticker\", \"date\", \"weighted_gdelt_tone_avg\", \"news_count\")\n",
    "try:\n",
    "    gold = spark.table(\"gold.ticker_predictor_training_dataset\")\n",
    "except:\n",
    "    gold = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c7a266a-2e75-455a-8a3f-6bce560d20dd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "filter by last record already in gold"
    }
   },
   "outputs": [],
   "source": [
    "if gold is not None:\n",
    "    last_valid = (gold\n",
    "        .filter(F.col(\"adj_close\").isNotNull() & F.col(\"weighted_gdelt_tone_avg\").isNotNull())\n",
    "        .groupBy(\"ticker\")\n",
    "        .agg(F.max(\"date\").alias(\"last_valid_date\"))\n",
    "    )\n",
    "    # Filtrar precios y noticias desde la última fecha válida + 1\n",
    "    prices = prices.join(last_valid, on=\"ticker\", how=\"left\") \\\n",
    "        .filter((F.col(\"last_valid_date\").isNull()) | (F.col(\"date\") > F.col(\"last_valid_date\"))) \\\n",
    "        .drop(\"last_valid_date\")\n",
    "    news = news.join(last_valid, on=\"ticker\", how=\"left\") \\\n",
    "        .filter((F.col(\"last_valid_date\").isNull()) | (F.col(\"date\") > F.col(\"last_valid_date\"))) \\\n",
    "        .drop(\"last_valid_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f18d5c23-2a20-4b01-825d-2efeed363d64",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "target variable"
    }
   },
   "outputs": [],
   "source": [
    "last_price_date = prices.groupBy(\"ticker\").agg(F.max(\"date\").alias(\"last_date\"))\n",
    "\n",
    "news = news.join(last_price_date, on=\"ticker\", how=\"inner\").filter(F.col(\"date\") <= F.col(\"last_date\")).drop(\"last_date\")\n",
    "\n",
    "w = W.partitionBy(\"ticker\").orderBy(\"date\")\n",
    "prices = (prices\n",
    "    .withColumn(\"adj_close_next\", F.lead(\"adj_close\", 1).over(w))\n",
    "    .withColumn(\"target_action\",\n",
    "        F.when(F.col(\"adj_close_next\") > F.col(\"adj_close\"), F.lit(\"buy\"))\n",
    "         .when(F.col(\"adj_close_next\") < F.col(\"adj_close\"), F.lit(\"sell\"))\n",
    "         .otherwise(F.lit(\"hold\"))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7dce179-8924-4874-a701-f8fd0885ae35",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "join and publish data"
    }
   },
   "outputs": [],
   "source": [
    "dataset = prices.join(news, on=[\"ticker\", \"date\"], how=\"left\")\n",
    "dataset = dataset.filter(F.col(\"ticker\").isNotNull() & F.col(\"date\").isNotNull())\n",
    "\n",
    "table_name = \"gold.ticker_predictor_training_dataset\"\n",
    "existing = None\n",
    "try:\n",
    "    existing = spark.table(table_name)\n",
    "except Exception:\n",
    "    existing = None\n",
    "\n",
    "if existing is not None:\n",
    "\n",
    "    joined = dataset.join(\n",
    "        existing.select(\"ticker\", \"date\", \"adj_close\", \"weighted_gdelt_tone_avg\"),\n",
    "        [\"ticker\", \"date\"],\n",
    "        \"left\"\n",
    "    )\n",
    "    # Registros nuevos: no existen en la tabla destino\n",
    "    new_rows = joined.filter(F.col(\"adj_close_y\").isNull())\n",
    "    # Registros modificados: existen pero algún campo relevante cambió\n",
    "    modified_rows = joined.filter(\n",
    "        (F.col(\"adj_close_y\").isNotNull()) & (\n",
    "            (F.col(\"adj_close\") != F.col(\"adj_close_y\")) |\n",
    "            (F.col(\"weighted_gdelt_tone_avg\") != F.col(\"weighted_gdelt_tone_avg_y\"))\n",
    "        )\n",
    "    )\n",
    "    print(f\"Registros nuevos: {new_rows.count()}\")\n",
    "    print(f\"Registros modificados: {modified_rows.count()}\")\n",
    "else:\n",
    "    print(f\"Registros nuevos: {dataset.count()}\")\n",
    "    print(\"Registros modificados: 0\")\n",
    "\n",
    "# Guardar el resultado\n",
    "dataset.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(table_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00-gold_ticker_predictor_training_dataset.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
